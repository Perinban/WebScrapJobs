name: Daily Web Scrap

on:
  schedule:
    - cron: "1 0 * * *"  # Runs daily at midnight UTC
  workflow_dispatch:
    inputs:
      scraper:
        description: "Choose which scraper to run"
        required: true
        default: "both"
        options:
          - "url"
          - "details"
          - "both"
          - "dummy"
      combine_upload:
        description: "Choose whether to combine and upload job summaries"
        required: true
        default: "yes"
        options:
          - "yes"
          - "no"

jobs:
  fetch-job-urls:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'both' }}
    concurrency:
      group: "fetch-job-urls-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job URL Scraper
        run: |
          if ! python script.py; then
            echo "Job URL scraper failed"
            exit 1
          fi

      - name: Commit and Push Job URLs
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
          if ! git diff --quiet job_post_url.txt; then
            git add job_post_url.txt
            git commit -m "Auto-update job_post_url.txt"
            git push origin main || echo "Push failed, possibly due to conflicts or branch protection."
          fi

      - name: Split Job URLs into Chunks
        run: python job-summary-splitter.py

      - name: Upload Job URL Chunks as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-urls
          path: job_urls_*.json

  fetch-job-details:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'both' }}
    concurrency:
      group: "fetch-job-details-${{ github.ref }}"
    needs: fetch-job-urls
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job URL Chunks
        uses: actions/download-artifact@v4
        with:
          name: job-urls
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: List Job URL Chunks
        id: list_files
        run: |
          files=$(ls job_urls_*.json | jq -R -s -c 'split("\n")[:-1] | map({"file": .})')
          if [ "$files" == "[]" ]; then
            echo "No job URL chunks found"
            exit 1
          fi
          echo "files=$files" >> $GITHUB_OUTPUT

  run-job-details:
    needs: fetch-job-details
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'both' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        file: ${{ fromJson(needs.fetch-job-details.outputs.files) }}
      max-parallel: 3
    concurrency:
      group: "run-job-details-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job Details Scraper
        run: |
          file_name="${{ matrix.file.file }}"
          chunk_number=$(echo "$file_name" | grep -oP '\d+')
          output_file="job_summary_${chunk_number}.json"
          if ! python job-details-scraper.py "$file_name" "$output_file"; then
            echo "Job details scraper failed"
            exit 1
          fi

      - name: Upload Job Summary Files as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-summaries
          path: job_summary_*.json

  combine-and-upload:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'both' }}
    concurrency:
      group: "combine-and-upload-${{ github.ref }}"
    needs: run-job-details
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job Summary Files
        uses: actions/download-artifact@v4
        with:
          name: job-summaries
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Combine Job Summary Files
        run: python combine-job-summaries.py

      - name: Upload to Google Drive
        env:
          GDRIVE_SERVICE_ACCOUNT_KEY: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_KEY }}
        run: |
          if [ -z "$GDRIVE_SERVICE_ACCOUNT_KEY" ]; then
            echo "GDRIVE_SERVICE_ACCOUNT_KEY is not set"
            exit 1
          fi
          python upload-to-gdrive.py

  manual-fetch-job-urls:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.scraper == 'url' }}
    concurrency:
      group: "fetch-job-urls-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job URL Scraper
        run: |
          if ! python script.py; then
            echo "Job URL scraper failed"
            exit 1
          fi

      - name: Commit and Push Job URLs
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          if ! git diff --quiet job_post_url.txt; then
            git add job_post_url.txt
            git commit -m "Auto-update job_post_url.txt"
            git push origin main || echo "Push failed, possibly due to conflicts or branch protection."
          fi

      - name: Split Job URLs into Chunks
        run: python job-summary-splitter.py

      - name: Upload Job URL Chunks as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-urls
          path: job_urls_*.json

  manual-fetch-job-details:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.scraper == 'details' }}
    concurrency:
      group: "fetch-job-details-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job URL Chunks
        uses: actions/download-artifact@v4
        with:
          name: job-urls
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: List Job URL Chunks
        id: list_files
        run: |
          files=$(ls job_urls_*.json | jq -R -s -c 'split("\n")[:-1] | map({"file": .})')
          if [ "$files" == "[]" ]; then
            echo "No job URL chunks found"
            exit 1
          fi
          echo "files=$files" >> $GITHUB_OUTPUT

  manual-run-job-details:
    needs: manual-fetch-job-details
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.scraper == 'details' }}
    strategy:
      matrix:
        file: ${{ fromJson(needs.manual-fetch-job-details.outputs.files) }}
      max-parallel: 3
    concurrency:
      group: "run-job-details-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job Details Scraper
        run: |
          file_name="${{ matrix.file.file }}"
          chunk_number=$(echo "$file_name" | grep -oP '\d+')
          output_file="job_summary_${chunk_number}.json"
          if ! python job-details-scraper.py "$file_name" "$output_file"; then
            echo "Job details scraper failed"
            exit 1
          fi

      - name: Upload Job Summary Files as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-summaries
          path: job_summary_*.json

  manual-combine-and-upload:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.scraper != 'both' && github.event.inputs.combine_upload == 'yes' }}
    concurrency:
      group: "combine-and-upload-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job Summary Files
        uses: actions/download-artifact@v4
        with:
          name: job-summaries
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Combine Job Summary Files
        run: python combine-job-summaries.py

      - name: Upload to Google Drive
        env:
          GDRIVE_SERVICE_ACCOUNT_KEY: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_KEY }}
        run: |
          if [ -z "$GDRIVE_SERVICE_ACCOUNT_KEY" ]; then
            echo "GDRIVE_SERVICE_ACCOUNT_KEY is not set"
            exit 1
          fi
          python upload-to-gdrive.py