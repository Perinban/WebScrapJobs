name: Daily Web Scrap

on:
  schedule:
    - cron: "1 0 * * *"  # Runs daily at midnight UTC
  workflow_dispatch:
    inputs:
      scraper:
        description: "Choose which scraper to run"
        required: true
        default: "both"
        options:
          - "url"
          - "details"
          - "both"
          - "dummy"
      combine_upload:
        description: "Choose whether to combine and upload job summaries"
        required: true
        default: "yes"
        options:
          - "yes"
          - "no"

jobs:
  fetch-job-urls:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'url' || github.event.inputs.scraper == 'both' }}  # Run only for 'url' or 'both'
    concurrency:
      group: "fetch-job-urls-${{ github.ref }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job URL Scraper
        run: python script.py

      - name: Commit and Push Job URLs
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
          # Check if job_post_url.txt has changes
          if ! git diff --quiet job_post_url.txt; then
            git add job_post_url.txt
            git commit -m "Auto-update job_post_url.txt"
            git push origin main
          fi

      - name: Split Job URLs into Chunks
        run: |
          python job_summary_splitter.py

      - name: Upload Job URL Chunks as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-urls
          path: job_urls_*.json

  fetch-job-details:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.scraper == 'details' || github.event.inputs.scraper == 'both' }}  # Run if 'details' or 'both' is selected
    concurrency:
      group: "fetch-job-details-${{ github.ref }}"
    needs: fetch-job-urls
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job URL Chunks
        uses: actions/download-artifact@v4
        with:
          name: job-urls
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Run Job Details Scraper
        run: |
          # Dynamically find all job_urls_*.json files and process them
          for file in job_urls_*.json; do
            chunk_number="${file//[^0-9]/}"  # Extract chunk number from file name
            output_file="job_summary_${chunk_number}.json"
            python job-details-scraper.py "$file" "$output_file"
          done

      - name: Upload Job Summary Files as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job-summaries
          path: job_summary_*.json

  combine-and-upload:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event.inputs.combine_upload == 'yes' }}
    concurrency:
      group: "combine-and-upload-${{ github.ref }}"
    needs: fetch-job-details
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Job Summary Files
        uses: actions/download-artifact@v4
        with:
          name: job-summaries
          path: .

      - name: Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt

      - name: Combine Job Summary Files
        run: |
          python combine-job-summaries.py

      - name: Upload to Google Drive
        env:
          GDRIVE_SERVICE_ACCOUNT_KEY: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_KEY }}
        run: |
          python upload-to-gdrive.py